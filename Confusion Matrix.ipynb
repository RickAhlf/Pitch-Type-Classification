{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CH', 'CU', 'FA', 'FC', 'FS', 'SI', 'SL']\n",
      "[[ 232    0   10    1    2    6    4]\n",
      " [   0  295    0    0    0    0   14]\n",
      " [  12    0 1432    3    0   60    5]\n",
      " [   0    0    1   30    0    1    2]\n",
      " [   1    0    0    0   14    0    0]\n",
      " [   2    0   37    0    0  161    0]\n",
      " [   0   13    4    4    0    0  517]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         CH       0.94      0.91      0.92       255\n",
      "         CU       0.96      0.95      0.96       309\n",
      "         FA       0.96      0.95      0.96      1512\n",
      "         FC       0.79      0.88      0.83        34\n",
      "         FS       0.88      0.93      0.90        15\n",
      "         SI       0.71      0.81      0.75       200\n",
      "         SL       0.95      0.96      0.96       538\n",
      "\n",
      "avg / total       0.94      0.94      0.94      2863\n",
      "\n",
      "['CH', 'CU', 'FA', 'SI', 'SL']\n",
      "[[ 73   0   3   1   1]\n",
      " [  0 124   0   0   0]\n",
      " [  2   0 307  18   0]\n",
      " [  0   0  14  78   0]\n",
      " [  2   0   0   0  84]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         CH       0.95      0.94      0.94        78\n",
      "         CU       1.00      1.00      1.00       124\n",
      "         FA       0.95      0.94      0.94       327\n",
      "         SI       0.80      0.85      0.83        92\n",
      "         SL       0.99      0.98      0.98        86\n",
      "\n",
      "avg / total       0.94      0.94      0.94       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Read training data (manually deleted rows 4296, 6420, 8516 - bad data)\n",
    "df = pd.read_csv(r'C:\\Users\\Rick Ahlf\\Downloads\\train.csv')\n",
    "\n",
    "#pitch_id is not included, mainly a surrogate index\n",
    "features = ['pitcher', 'batter_side', 'inning', 'half',\n",
    "   'outs', 'balls', 'strikes', 'x55', 'y55', 'z55', 'vx55', 'vy55', 'vz55',\n",
    "   'ax', 'ay', 'az', 'pitch_speed', 'release_x', 'release_z',\n",
    "   'release_angle_x', 'release_angle_z', 'extension', 'break_x', 'break_z',\n",
    "   'induced_break_z', 'spin_rate', 'spin_axis', 'pfx_x', 'pfx_z',\n",
    "   'pfx_xLONG', 'pfx_zLONG', 'approach_angle_x', 'approach_angle_z',\n",
    "   'plate_x', 'plate_z']\n",
    "\n",
    "#Convert Left/Right to 1/0\n",
    "df['pitcher_side'] = np.where(df['pitcher_side']=='Left', 1, 0)\n",
    "df['batter_side'] = np.where(df['batter_side']=='Left', 1, 0)\n",
    "\n",
    "#Convert pitcher from categorical to numeric\n",
    "le = LabelEncoder()\n",
    "df['pitcher'] = le.fit_transform(df['pitcher'])\n",
    "\n",
    "for p in df['pitcher_side'].unique():\n",
    "\n",
    "    df_p = df[df['pitcher_side']==p].reset_index()\n",
    "\n",
    "    #Split into training and test sets\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df_p.loc[:, features], df_p['type'], test_size=0.2, random_state=0)\n",
    "\n",
    "    #Standardize data set to unit scale (mean = 0 and variance = 1)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #Fit on training set only\n",
    "    scaler.fit(train_x)\n",
    "\n",
    "    #Apply transform to both the training set and the test set\n",
    "    train_x = scaler.transform(train_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "\n",
    "    #Neural network\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(25,25,25), max_iter=500)\n",
    "\n",
    "    #Apply PCA\n",
    "    pca = PCA(n_components=16)\n",
    "    pca.fit(train_x, train_y)\n",
    "\n",
    "    #Evaluate PCA pipeline\n",
    "    pipe = Pipeline([('pca', pca), ('neural network', mlp)])\n",
    "    pipe.fit(train_x, train_y)\n",
    "    predictions = pipe.predict(test_x)\n",
    "\n",
    "    #Confusion matrix and classification report\n",
    "    print(sorted(test_y.unique()))\n",
    "    print(confusion_matrix(test_y, predictions))\n",
    "    print(classification_report(test_y, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
